<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepSeek-R1 1.5B</title>
    <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; margin: 20px; }
        h1, h2 { color: #333; }
        pre { background: #f4f4f4; padding: 10px; border-radius: 5px; overflow-x: auto; }
        code { font-family: monospace; }
        a { color: #007BFF; text-decoration: none; }
        a:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <h1>DeepSeek-R1 1.5B</h1>
    <p><strong>Nota:</strong> Antes de come√ßar, certifique-se de que j√° instalou o Ollama seguindo este guia: <a href="https://github.com/Agents4Good/CozinhaLLM/blob/main/content/ollama/install.md">Ollama - Instala√ß√£o</a></p>
    
    <h2>Executando o DeepSeek no Ollama</h2>
    <p>Teste o DeepSeek diretamente pelo terminal com o seguinte comando:</p>
    <pre><code>ollama run deepseek-r1:1.5b</code></pre>
    
    <h2>Informa√ß√µes do Modelo</h2>
    <p>Visualize informa√ß√µes detalhadas do modelo utilizando o comando:</p>
    <pre><code>/show info</code></pre>
    
    <h2>Configurando um Ambiente Virtual</h2>
    <h3>Instale o Virtualenv</h3>
    <pre><code>pip install virtualenv</code></pre>
    
    <h3>Crie um diret√≥rio para o projeto e acesse-o</h3>
    <pre><code>cd my-project</code></pre>
    
    <h3>Crie o ambiente virtual</h3>
    <pre><code>python -m venv venv</code></pre>
    
    <h3>Ative o ambiente virtual</h3>
    <p>üîπ <strong>Windows:</strong></p>
    <pre><code>venv\Scripts\activate</code></pre>
    <p>üîπ <strong>Linux/Mac:</strong></p>
    <pre><code>source venv/bin/activate</code></pre>
    
    <h3>Desativando o ambiente virtual</h3>
    <pre><code>deactivate</code></pre>
    <p>Para reativar, basta executar novamente o comando de ativa√ß√£o.</p>
    
    <p>Ficou com d√∫vidas sobre o ambiente virtual? Acesse os links a seguir:</p>
    <ul>
        <li><a href="https://dev.to/franciscojdsjr/guia-completo-para-usar-o-virtual-environment-venv-no-python-57bo">Tutorial Completo Venv - Medium</a></li>
        <li><a href="https://docs.python.org/pt-br/3.13/library/venv.html">Documenta√ß√£o</a></li>
    </ul>
    
    <h2>Instalando a Biblioteca Ollama</h2>
    <pre><code>pip install ollama</code></pre>
    
    <h2>Configura√ß√£o no VSCode</h2>
    <p>Abra o diret√≥rio do seu projeto no <strong>VSCode</strong> e certifique-se de que est√° usando o ambiente virtual correto.</p>
    <img src="https://github.com/user-attachments/assets/34483997-5cc7-4428-9967-2c648cef13f2" alt="Configura√ß√£o no VSCode" width="100%">
    
    <h2>Exemplo de C√≥digo em Python e Ollama</h2>
    <pre><code>from ollama import chat
from ollama import ChatResponse

response: ChatResponse = chat(model='deepseek-r1:1.5b', messages=[
  {
    'role': 'user',
    'content': 'Why is the sky blue?',
  },
])

print(response.message.content)</code></pre>
    <p><strong>Nota:</strong> Caso enfrente erros ao acessar a biblioteca <em>ollama</em>, verifique se o ambiente virtual est√° ativo.</p>
    
    <h2>LangChain</h2>
    <p>Para facilitar nossas vidas, existe um framework chamado <strong>LangChain</strong>, que potencializa nossas aplica√ß√µes de IA.</p>
    <p>Veja o mesmo c√≥digo mostrado na se√ß√£o anterior, mas dessa vez com o <strong>LangChain</strong>.</p>
    <pre><code>from langchain_ollama import ChatOllama

chat = ChatOllama(model="deepseek-r1:1.5b")

response = chat.invoke("Why is the sky blue?")
print(response.content)</code></pre>
    
    <p><strong>Nota:</strong> No t√≥pico "Aplica√ß√µes", h√° exemplos de uso do LangChain.</p>
</body>
</html>
